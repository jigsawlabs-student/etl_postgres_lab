{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "express-fishing",
   "metadata": {},
   "source": [
    "# Foursquare Star"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mineral-arabic",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accomplished-pressure",
   "metadata": {},
   "source": [
    "In this lesson, we'll practice working with our foursquare domain to perform ETL in postgres.  We'll do this to copy our data from a schema that fits OLTP to one that fits a OLAP structure.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colonial-machine",
   "metadata": {},
   "source": [
    "### Loading the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "taken-filter",
   "metadata": {},
   "source": [
    "Skip this section if you already have a foursquare database in postgres, otherwise, follow the following steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decent-accessory",
   "metadata": {},
   "source": [
    "* Create a database called `foursquare_practice`.\n",
    "* Do so from the command line with the -c flag.\n",
    "\n",
    "\n",
    "Then run the migrations in the `db/migrations/create_tables.sql` file.\n",
    "\n",
    "Now that our database and related tables are created, let's load in some data. We have a number of CSV files in the `foursquare-fullstack/data` folder. We can copy in the data into our tables with a command in the following format:\n",
    "```SQL\n",
    "COPY table_name\n",
    "FROM 'absolute/path/to/data.csv' \n",
    "DELIMITER ',' \n",
    "CSV HEADER;\n",
    "```\n",
    "Load in each csv file in the data folder to the related table.\n",
    "\n",
    "> Note: Begin with the least dependent tables (eg. states then cities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "combined-dallas",
   "metadata": {},
   "source": [
    "### Reviewing Foursquare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afraid-piano",
   "metadata": {},
   "source": [
    "Once our database schema is setup and our data is loaded, let's connect to our foursquare database, and take a look at the various tables in our OLTP schema.  Our starting foursquare schema looks like the following."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "looking-tuesday",
   "metadata": {},
   "source": [
    "> <img src=\"./oltp_venue.png\" width=\"80%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regulated-separate",
   "metadata": {},
   "source": [
    "And we'll move this data to a star schema that takes on the following structure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finished-course",
   "metadata": {},
   "source": [
    "> <img src=\"./updated_star.png\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regional-abuse",
   "metadata": {},
   "source": [
    "So above we have a fact table of venues, and dimension tables of locations and categories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dominant-companion",
   "metadata": {},
   "source": [
    "To get there, the main steps that we'll need to perform is to select the data spread across zipcodes, cities and states tables in our OLTP structure and then move it into the `locations` table.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unknown-modeling",
   "metadata": {},
   "source": [
    "### Creating our Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amateur-treasure",
   "metadata": {},
   "source": [
    "Ok, our first step is to create our new tables.  To that end we have created a `star_schema.sql` file located in the root directory of the lab.  \n",
    "\n",
    "Take a look through the file, and then run the migrations using the `-f` flag against the `foursquare_practice` database.\n",
    "\n",
    "Let's take a look at one of the tables, `dimcategories`:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "settled-constant",
   "metadata": {},
   "source": [
    "```SQL\n",
    "CREATE TABLE IF NOT EXISTS dimcategories (\n",
    "  id serial PRIMARY KEY,\n",
    "  name VARCHAR(255),\n",
    "  venue_id INTEGER,\n",
    "  CONSTRAINT fk_venue\n",
    "  FOREIGN KEY (venue_id)\n",
    "  REFERENCES factvenues (id)\n",
    ");\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chemical-choice",
   "metadata": {},
   "source": [
    "So one of the key changes here is that we no longer have a constraint that a category's `name` be unique.  The reason is because now that we are moving away from third normal form (3NF), we will repeat categories like`Pizza Place` for every pizza venue, and simply have a different venue_idÂ for each record.  This means we can no longer use the unique constraint. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respective-province",
   "metadata": {},
   "source": [
    "### Copying Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "everyday-longer",
   "metadata": {},
   "source": [
    "Ok, now let's work on copying over our data.  Let's start with the dimension table of locations. \n",
    "\n",
    "> We do this because it is the only table that does not have a foreign key.\n",
    "\n",
    "We'll do this in two steps.  First, we'll make sure we are selecting the correct data by only select the correct data and not inserting it.  Then after we know we are selecting the right data, we can move it to the right table with an  `INSERT INTO..SELECT` command."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medium-explanation",
   "metadata": {},
   "source": [
    "> First, we connect to the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "recreational-philippines",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "def get_cursor():\n",
    "    conn = psycopg2.connect(\n",
    "    host=\"127.0.0.1\",\n",
    "    database=\"foursquare_development\",\n",
    "    user=\"postgres\",\n",
    "    password=\"postgres\")\n",
    "    \n",
    "    cursor = conn.cursor()\n",
    "    return conn, cursor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "precious-disposition",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn, cursor = get_cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smaller-isolation",
   "metadata": {},
   "source": [
    "> And now simply select (without inserting in) the data needed for the `dimlocations` table and limit to two rows of data.  Also select the location id value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "rotary-river",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(\"\"\"SELECT locations.id, latitude, longitude, code, cities.name, states.name \n",
    "FROM locations \n",
    "JOIN zipcodes ON locations.zipcode_id = zipcodes.id\n",
    "JOIN cities ON zipcodes.city_id = cities.id\n",
    "JOIN states ON cities.state_id = states.id LIMIT 2;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "smooth-athens",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(50, Decimal('-73.9875'), Decimal('40.7024'), 11210, 'New York', 'New York'),\n",
       " (51, Decimal('-73.9875'), Decimal('40.7024'), 11210, 'New York', 'New York')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor.fetchall()\n",
    "# [(50, Decimal('-73.9875'), Decimal('40.7024'), 11210, 'New York', 'New York'),\n",
    "#  (51, Decimal('-73.9875'), Decimal('40.7024'), 11210, 'New York', 'New York')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "representative-toronto",
   "metadata": {},
   "source": [
    "Ok, now that we have the `SELECT` component working, we can add in our `INSERT INTO` statement.  We'll have the id be equal to our original locations id in the OLTP.  This will help us find the original data as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "demanding-cricket",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(\"\"\"\n",
    "INSERT INTO dimlocations (id, longitude, latitude, address, zipcode, city, state)\n",
    "SELECT locations.id, longitude, latitude, address, code, cities.name, states.name \n",
    "FROM locations \n",
    "JOIN zipcodes ON locations.zipcode_id = zipcodes.id\n",
    "JOIN cities ON zipcodes.city_id = cities.id\n",
    "JOIN states ON cities.state_id = states.id;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "revised-ending",
   "metadata": {},
   "source": [
    "Then we'll need to commit the change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "postal-short",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "international-yesterday",
   "metadata": {},
   "source": [
    "And we can confirm that our command worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "worse-sleeve",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute('SELECT * FROM dimlocations LIMIT 1;')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "innocent-circus",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(50,\n",
       "  Decimal('40.7024'),\n",
       "  Decimal('-73.9875'),\n",
       "  '141 Front Street',\n",
       "  '11210',\n",
       "  'New York',\n",
       "  'New York')]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor.fetchall()\n",
    "# [(50, Decimal('40.7024'), Decimal('-73.9875'), '141 Front Street', '11210', 'New York', 'New York')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "arbitrary-chaos",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(134,)]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor.execute('SELECT COUNT(*) FROM dimlocations LIMIT 1;')\n",
    "cursor.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signed-avatar",
   "metadata": {},
   "source": [
    "Ok, now let's take care of the `factvenues` table.  We'll need the `id`, `name`, `location_id`, `price`, `rating`, and `likes`.  The `id` should match the venue id of the venues table, and the `location_id` can match the `location_id` from the original OLTP schema.\n",
    "\n",
    "When you feel comfortable, insert the data into factvenues table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "surprising-scenario",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn, cursor = get_cursor()\n",
    "\n",
    "cursor.execute(\"\"\"\n",
    "INSERT INTO factvenues (id, name, location_id, price, rating, likes)\n",
    "SELECT venues.id, venues.name, locations.id, price, rating, likes FROM venues\n",
    "JOIN locations ON venues.id = locations.venue_id;\n",
    "\"\"\")\n",
    "\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "objective-transcript",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(\"SELECT * FROM factvenues LIMIT 5;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "dental-eclipse",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(53, 'Los Tacos Al Pastor', 50, 1, None, None),\n",
       " (54, 'Grimaldis', 51, 2, Decimal('2'), 3),\n",
       " (55, 'Cafe Mogador', 52, 3, Decimal('4'), 15),\n",
       " (56, 'Zahavs', 53, 4, Decimal('5'), 100),\n",
       " (57, 'Los Tacos Al Pastor', 54, 1, Decimal('8.0'), 52)]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor.fetchall()\n",
    "# [(53, 'Los Tacos Al Pastor', 50, 1, None, None),\n",
    "#  (54, 'Grimaldis', 51, 2, Decimal('2'), 3),\n",
    "#  (55, 'Cafe Mogador', 52, 3, Decimal('4'), 15),\n",
    "#  (56, 'Zahavs', 53, 4, Decimal('5'), 100),\n",
    "#  (57, 'Los Tacos Al Pastor', 54, 1, Decimal('8.0'), 52)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "white-trouble",
   "metadata": {},
   "source": [
    "And the last step is our `dimcategories` table.  Here, we'll need to insert in the `venue_id`, and category `name`.  Again, it's beneficial to begin with the SELECT statement and then move to the INSERT INTO statement.\n",
    "\n",
    "> Here, we can set the id equal to the `venue_categories.id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "institutional-accordance",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(\"\"\"\n",
    "INSERT INTO dimcategories (id, venue_id, name)\n",
    "SELECT venue_categories.id, venue_id, categories.name FROM venue_categories \n",
    "JOIN categories ON categories.id = venue_categories.category_id LIMIT 4;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "cleared-healthcare",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "addressed-hawaiian",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(\"SELECT * FROM dimcategories LIMIT 2;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "personal-tunnel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(68, 'Pizza', 54), (69, 'Italian', 54)]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor.fetchall()\n",
    "# [(68, 'Pizza', 54), (69, 'Italian', 54)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amino-acrylic",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "understood-pierre",
   "metadata": {},
   "source": [
    "In this lesson, we practiced migrating our data from the OLTP schema to the OLAP schema.  We broke this into two steps: we first made sure that we had the `SELECT` statement working properly, and then we added in the `INSERT INTO` component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dense-chicken",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
