{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "designed-solid",
   "metadata": {},
   "source": [
    "# Foursquare Star"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viral-classics",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indie-martin",
   "metadata": {},
   "source": [
    "In this lesson, we'll practice working with our foursquare domain to perform ETL in postgres.  We'll do this to copy our data from a schema that fits OLTP to one that fits a OLAP structure.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "united-check",
   "metadata": {},
   "source": [
    "### Loading the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hawaiian-gender",
   "metadata": {},
   "source": [
    "Skip this section if you already have a foursquare database in postgres, otherwise, follow the following steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "understood-olive",
   "metadata": {},
   "source": [
    "Then let's set up our database.\n",
    "\n",
    "* Create a database called `foursquare_practice`.\n",
    "* Do so from the command line with the -c flag.\n",
    "\n",
    "\n",
    "Then run the migrations in the `db/migrations/create_tables.sql` file.\n",
    "\n",
    "Now that our database and related tables are created, let's load in some data. We have a number of CSV files in the `/data` folder. We can copy in the data into our tables with a command in the following format:\n",
    "```SQL\n",
    "COPY table_name\n",
    "FROM 'absolute/path/to/data.csv' \n",
    "DELIMITER ',' \n",
    "CSV HEADER;\n",
    "```\n",
    "Load in each csv file in the data folder to the related table.\n",
    "\n",
    "> Note: Begin with the least dependent tables (eg. states then cities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "current-mississippi",
   "metadata": {},
   "source": [
    "### Reviewing Foursquare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acoustic-amsterdam",
   "metadata": {},
   "source": [
    "Next, let's connect to our foursquare database, and take a look at the various tables in our OLTP schema.  So our starting foursquare schema looks like the following."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "short-salad",
   "metadata": {},
   "source": [
    "> <img src=\"./oltp_venue.png\" width=\"80%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functional-mobility",
   "metadata": {},
   "source": [
    "So currently, the main steps that we'll need to get this into a star schema is to select the data spread across zicodes, cities and states, and move it to the locations table.  If we accomplish this, we can move our data to this structure with the star schema."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dangerous-pavilion",
   "metadata": {},
   "source": [
    "> <img src=\"./updated_star.png\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposed-questionnaire",
   "metadata": {},
   "source": [
    "Before moving on, let's again appreciate how this structure helps us.  \n",
    "\n",
    "Off the bat, this database structure is simpler, and follows how we think of a venue conceptually: it has one location and many categories.  \n",
    "\n",
    "> So our fact table is venues and we have dimension tables of catgeories and locations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compressed-sterling",
   "metadata": {},
   "source": [
    "### Creating our Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tribal-alpha",
   "metadata": {},
   "source": [
    "Ok, our first step is to create our new tables.  To that end we have created a `star_schema.sql` file.  Take a look through the file, and then run the migrations using the `-f` flag against the `foursquare_practice` database.\n",
    "\n",
    "Let's take a look at one of the tables:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "african-retrieval",
   "metadata": {},
   "source": [
    "```SQL\n",
    "CREATE TABLE IF NOT EXISTS dimcategories (\n",
    "  id serial PRIMARY KEY,\n",
    "  name VARCHAR(255),\n",
    "  venue_id INTEGER,\n",
    "  CONSTRAINT fk_venue\n",
    "  FOREIGN KEY (venue_id)\n",
    "  REFERENCES factvenues (id)\n",
    ");\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appreciated-quarter",
   "metadata": {},
   "source": [
    "One of the key changes here is that we no longer have a constraint that a category's `name` be unique.  The reason is because now that we have moved away from third normal form (3NF), for each pizza restaurant we will repeat the name `Pizza Place`, and have a different venue_idÂ for the record.  So we can no longer use the unique constraint. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "constant-somewhere",
   "metadata": {},
   "source": [
    "### Copying Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorrect-format",
   "metadata": {},
   "source": [
    "Ok, now let's work with copying over our data.  Let's start with the dimension table of locations. \n",
    "\n",
    "> We do this because it is the only table that does not have a foreign key.\n",
    "\n",
    "We'll start by simply using a `SELECT` command to make sure you are selecting the correct data, and then we can move to an `INSERT INTO..SELECT` command once this looks correct."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wireless-feedback",
   "metadata": {},
   "source": [
    "> So select the data needed for the `dimlocations` table and limit to two rows of data.  Also select the location id value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "universal-hartford",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "def get_cursor():\n",
    "    conn = psycopg2.connect(\n",
    "    host=\"127.0.0.1\",\n",
    "    database=\"foursquare_development\",\n",
    "    user=\"postgres\",\n",
    "    password=\"postgres\")\n",
    "    \n",
    "    cursor = conn.cursor()\n",
    "    return conn, cursor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "worth-naples",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn, cursor = get_cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "agreed-skirt",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(\"\"\"SELECT locations.id, latitude, longitude, code, cities.name, states.name \n",
    "FROM locations \n",
    "JOIN zipcodes ON locations.zipcode_id = zipcodes.id\n",
    "JOIN cities ON zipcodes.city_id = cities.id\n",
    "JOIN states ON cities.state_id = states.id LIMIT 2;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "wicked-guard",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(50, Decimal('-73.9875'), Decimal('40.7024'), 11210, 'New York', 'New York'),\n",
       " (51, Decimal('-73.9875'), Decimal('40.7024'), 11210, 'New York', 'New York')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor.fetchall()\n",
    "# [(50, Decimal('-73.9875'), Decimal('40.7024'), 11210, 'New York', 'New York'),\n",
    "#  (51, Decimal('-73.9875'), Decimal('40.7024'), 11210, 'New York', 'New York')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unauthorized-basin",
   "metadata": {},
   "source": [
    "Ok, now that we have the SELECT working, we can add in our insert into statement.  We'll have the id be equal to our original locations id in the OLTP.  This will help us find the original data as needed (and we'll see, will provide us some benefits later on.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "thirty-label",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(\"\"\"\n",
    "INSERT INTO dimlocations (id, longitude, latitude, address, zipcode, city, state)\n",
    "SELECT locations.id, longitude, latitude, address, code, cities.name, states.name \n",
    "FROM locations \n",
    "JOIN zipcodes ON locations.zipcode_id = zipcodes.id\n",
    "JOIN cities ON zipcodes.city_id = cities.id\n",
    "JOIN states ON cities.state_id = states.id;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "remarkable-appearance",
   "metadata": {},
   "source": [
    "Then we'll need to commit the change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organizational-algeria",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dependent-tomorrow",
   "metadata": {},
   "source": [
    "And we can confirm that our command worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "departmental-melbourne",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute('SELECT * FROM dimlocations LIMIT 1;')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "loved-circuit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(50,\n",
       "  Decimal('40.7024'),\n",
       "  Decimal('-73.9875'),\n",
       "  '141 Front Street',\n",
       "  '11210',\n",
       "  'New York',\n",
       "  'New York')]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor.fetchall()\n",
    "# [(50, Decimal('40.7024'), Decimal('-73.9875'), '141 Front Street', '11210', 'New York', 'New York')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "physical-tension",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(134,)]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor.execute('SELECT COUNT(*) FROM dimlocations LIMIT 1;')\n",
    "cursor.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "provincial-bloom",
   "metadata": {},
   "source": [
    "Ok, now let's take care of the `factvenues` table.  We need the id, name, location_id, price, rating, and likes.  The `id` should match the venue id of the venues table, and the `location_id` can match the `location_id` from the original OLTP schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "continuing-colorado",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn, cursor = get_cursor()\n",
    "\n",
    "cursor.execute(\"\"\"\n",
    "INSERT INTO factvenues (id, name, location_id, price, rating, likes)\n",
    "SELECT venues.id, venues.name, locations.id, price, rating, likes FROM venues\n",
    "JOIN locations ON venues.id = locations.venue_id;\n",
    "\"\"\")\n",
    "\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "sought-serial",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(\"SELECT * FROM factvenues LIMIT 5;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "employed-consciousness",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(53, 'Los Tacos Al Pastor', 50, 1, None, None),\n",
       " (54, 'Grimaldis', 51, 2, Decimal('2'), 3),\n",
       " (55, 'Cafe Mogador', 52, 3, Decimal('4'), 15),\n",
       " (56, 'Zahavs', 53, 4, Decimal('5'), 100),\n",
       " (57, 'Los Tacos Al Pastor', 54, 1, Decimal('8.0'), 52)]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor.fetchall()\n",
    "# [(53, 'Los Tacos Al Pastor', 50, 1, None, None),\n",
    "#  (54, 'Grimaldis', 51, 2, Decimal('2'), 3),\n",
    "#  (55, 'Cafe Mogador', 52, 3, Decimal('4'), 15),\n",
    "#  (56, 'Zahavs', 53, 4, Decimal('5'), 100),\n",
    "#  (57, 'Los Tacos Al Pastor', 54, 1, Decimal('8.0'), 52)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rocky-philip",
   "metadata": {},
   "source": [
    "Ok, the last step is our `dimcategories` table.  Here, we'll need to insert in the `venue_id`, and category `name`.  Again, it's beneficial to begin with the SELECT statement and then move to the INSERT INTO statement.\n",
    "\n",
    "> Here, we can set the id equal to the venue_categories.id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "alone-compression",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(\"\"\"\n",
    "INSERT INTO dimcategories (id, venue_id, name)\n",
    "SELECT venue_categories.id, venue_id, categories.name FROM venue_categories \n",
    "JOIN categories ON categories.id = venue_categories.category_id LIMIT 4;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "aboriginal-barrier",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "scientific-responsibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(\"SELECT * FROM dimcategories LIMIT 2;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "biological-acrylic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(68, 'Pizza', 54), (69, 'Italian', 54)]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor.fetchall()\n",
    "# [(68, 'Pizza', 54), (69, 'Italian', 54)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "religious-preview",
   "metadata": {},
   "source": [
    "### Reviewing OLAP cubes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comic-comparison",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "regulated-force",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "photographic-ultimate",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
